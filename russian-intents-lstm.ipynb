{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2560015,"sourceType":"datasetVersion","datasetId":1549969}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T08:15:05.146471Z","iopub.execute_input":"2024-05-29T08:15:05.146937Z","iopub.status.idle":"2024-05-29T08:15:06.221216Z","shell.execute_reply.started":"2024-05-29T08:15:05.146881Z","shell.execute_reply":"2024-05-29T08:15:06.220055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn\nimport timeit","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:06.223258Z","iopub.execute_input":"2024-05-29T08:15:06.223882Z","iopub.status.idle":"2024-05-29T08:15:11.719438Z","shell.execute_reply.started":"2024-05-29T08:15:06.223847Z","shell.execute_reply":"2024-05-29T08:15:11.718009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import Dataset \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.720964Z","iopub.execute_input":"2024-05-29T08:15:11.721479Z","iopub.status.idle":"2024-05-29T08:15:11.867935Z","shell.execute_reply.started":"2024-05-29T08:15:11.721444Z","shell.execute_reply":"2024-05-29T08:15:11.866695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.869643Z","iopub.execute_input":"2024-05-29T08:15:11.870114Z","iopub.status.idle":"2024-05-29T08:15:11.876399Z","shell.execute_reply.started":"2024-05-29T08:15:11.870073Z","shell.execute_reply":"2024-05-29T08:15:11.874758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_train.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntest_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_test.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.880415Z","iopub.execute_input":"2024-05-29T08:15:11.880811Z","iopub.status.idle":"2024-05-29T08:15:11.954569Z","shell.execute_reply.started":"2024-05-29T08:15:11.880784Z","shell.execute_reply":"2024-05-29T08:15:11.953338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data = pd.concat([train_data, test_data])\nfull_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.956027Z","iopub.execute_input":"2024-05-29T08:15:11.956421Z","iopub.status.idle":"2024-05-29T08:15:11.968551Z","shell.execute_reply.started":"2024-05-29T08:15:11.956390Z","shell.execute_reply":"2024-05-29T08:15:11.967398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\nunique_values_normalized = train['intent'].value_counts(normalize=True)\nprint(unique_values_normalized*100)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.970029Z","iopub.execute_input":"2024-05-29T08:15:11.970450Z","iopub.status.idle":"2024-05-29T08:15:11.996647Z","shell.execute_reply.started":"2024-05-29T08:15:11.970412Z","shell.execute_reply":"2024-05-29T08:15:11.995393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:11.998163Z","iopub.execute_input":"2024-05-29T08:15:11.998690Z","iopub.status.idle":"2024-05-29T08:15:12.006095Z","shell.execute_reply.started":"2024-05-29T08:15:11.998639Z","shell.execute_reply":"2024-05-29T08:15:12.004594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Добавление дополнительного измерения\n#         print(f'x shape: {x.shape}')\n        lstm_out, _ = self.lstm(x)\n        out = self.fc(lstm_out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:12.007620Z","iopub.execute_input":"2024-05-29T08:15:12.008029Z","iopub.status.idle":"2024-05-29T08:15:12.019844Z","shell.execute_reply.started":"2024-05-29T08:15:12.007998Z","shell.execute_reply":"2024-05-29T08:15:12.018740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !\nfrom sklearn.preprocessing import LabelEncoder\n\n# Создание LabelEncoder\nle = LabelEncoder()\n\n# Подготовка данных\nfull_data = pd.concat([train_data, test_data])\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n# # Токенизация и преобразование в TF-IDF\n# tokenizer = word_tokenize\n# vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\n\n# train_texts = vectorizer.fit_transform(train['text']).toarray()\n# test_texts = vectorizer.transform(test['text']).toarray()\n\n# # Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\n# train_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\n# test_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:12.021279Z","iopub.execute_input":"2024-05-29T08:15:12.021683Z","iopub.status.idle":"2024-05-29T08:15:12.041182Z","shell.execute_reply.started":"2024-05-29T08:15:12.021651Z","shell.execute_reply":"2024-05-29T08:15:12.039933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Токенизация и преобразование в TF-IDF\ntokenizer = word_tokenize\nvectorizer = TfidfVectorizer(tokenizer=tokenizer)\n\ntrain_texts = vectorizer.fit_transform(train['text']).toarray()\ntest_texts = vectorizer.transform(test['text']).toarray()\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\ntest_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:12.042461Z","iopub.execute_input":"2024-05-29T08:15:12.042836Z","iopub.status.idle":"2024-05-29T08:15:13.809604Z","shell.execute_reply.started":"2024-05-29T08:15:12.042803Z","shell.execute_reply":"2024-05-29T08:15:13.808350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подготовка данных\n# full_data = pd.concat([train_data, test_data])\n# train, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# le = LabelEncoder()\n# train_labels = le.fit_transform(train['intent'])\n# test_labels = le.transform(test['intent'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:13.811057Z","iopub.execute_input":"2024-05-29T08:15:13.811418Z","iopub.status.idle":"2024-05-29T08:15:13.819036Z","shell.execute_reply.started":"2024-05-29T08:15:13.811388Z","shell.execute_reply":"2024-05-29T08:15:13.817716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_texts.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25\n\nfor epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for i, (texts, labels) in enumerate(tqdm(train_loader)):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for i, (texts, labels) in enumerate(tqdm(test_loader)):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:13.820593Z","iopub.execute_input":"2024-05-29T08:15:13.821000Z","iopub.status.idle":"2024-05-29T08:18:31.559325Z","shell.execute_reply.started":"2024-05-29T08:15:13.820967Z","shell.execute_reply":"2024-05-29T08:18:31.557976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(balanced_accuracy_score(test_labels, predictions))\n# print(precision_recall_fscore_support(test_labels, predictions, average = 'weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:31.563748Z","iopub.execute_input":"2024-05-29T08:18:31.564324Z","iopub.status.idle":"2024-05-29T08:18:32.136255Z","shell.execute_reply.started":"2024-05-29T08:18:31.564291Z","shell.execute_reply":"2024-05-29T08:18:32.135088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(balanced_accuracy_score(test_labels, predictions))\nprint(precision_recall_fscore_support(test_labels, predictions, average='weighted'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mini-LM","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:32.137346Z","iopub.execute_input":"2024-05-29T08:18:32.137746Z","iopub.status.idle":"2024-05-29T08:18:32.729311Z","shell.execute_reply.started":"2024-05-29T08:18:32.137713Z","shell.execute_reply":"2024-05-29T08:18:32.728241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:32.730736Z","iopub.execute_input":"2024-05-29T08:18:32.731113Z","iopub.status.idle":"2024-05-29T08:18:32.738075Z","shell.execute_reply.started":"2024-05-29T08:18:32.731076Z","shell.execute_reply":"2024-05-29T08:18:32.736804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание пользовательского Dataset класса\nclass TextDataset(Dataset):\n    def __init__(self, embeddings, labels):\n        self.embeddings = embeddings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.embeddings[idx], self.labels[idx]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:32.739600Z","iopub.execute_input":"2024-05-29T08:18:32.740075Z","iopub.status.idle":"2024-05-29T08:18:32.748689Z","shell.execute_reply.started":"2024-05-29T08:18:32.740042Z","shell.execute_reply":"2024-05-29T08:18:32.747471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Определение модели LSTM\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(LSTMClassifier, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        _, (hn, _) = self.lstm(x.unsqueeze(1))\n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:32.750274Z","iopub.execute_input":"2024-05-29T08:18:32.750889Z","iopub.status.idle":"2024-05-29T08:18:32.762116Z","shell.execute_reply.started":"2024-05-29T08:18:32.750837Z","shell.execute_reply":"2024-05-29T08:18:32.761040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n\n# Load your dataset\ntrain_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_train.tsv', delimiter='\\t', encoding=\"utf-8\", names=['text', 'intent'])\ntest_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_test.tsv', delimiter='\\t', encoding=\"utf-8\", names=['text', 'intent'])\nfull_data = pd.concat([train_data, test_data])\n\n# Split the data into train and test sets\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Extract embeddings\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).pooler_output\n    test_embeddings = model(**test_encodings).pooler_output\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:18:32.763704Z","iopub.execute_input":"2024-05-29T08:18:32.764098Z","iopub.status.idle":"2024-05-29T08:25:34.372397Z","shell.execute_reply.started":"2024-05-29T08:18:32.764065Z","shell.execute_reply":"2024-05-29T08:25:34.370053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25\n\nfor epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.373836Z","iopub.status.idle":"2024-05-29T08:25:34.374452Z","shell.execute_reply.started":"2024-05-29T08:25:34.374151Z","shell.execute_reply":"2024-05-29T08:25:34.374178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.376218Z","iopub.status.idle":"2024-05-29T08:25:34.376812Z","shell.execute_reply.started":"2024-05-29T08:25:34.376521Z","shell.execute_reply":"2024-05-29T08:25:34.376549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.378447Z","iopub.status.idle":"2024-05-29T08:25:34.379041Z","shell.execute_reply.started":"2024-05-29T08:25:34.378752Z","shell.execute_reply":"2024-05-29T08:25:34.378778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"M-USE","metadata":{}},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")\nmodel = AutoModel.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.381355Z","iopub.status.idle":"2024-05-29T08:25:34.382254Z","shell.execute_reply.started":"2024-05-29T08:25:34.381851Z","shell.execute_reply":"2024-05-29T08:25:34.381878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Извлечение эмбеддингов\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).last_hidden_state.mean(dim=1)\n    test_embeddings = model(**test_encodings).last_hidden_state.mean(dim=1)\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.383921Z","iopub.status.idle":"2024-05-29T08:25:34.384467Z","shell.execute_reply.started":"2024-05-29T08:25:34.384200Z","shell.execute_reply":"2024-05-29T08:25:34.384226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.385749Z","iopub.status.idle":"2024-05-29T08:25:34.386288Z","shell.execute_reply.started":"2024-05-29T08:25:34.386020Z","shell.execute_reply":"2024-05-29T08:25:34.386045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.388041Z","iopub.status.idle":"2024-05-29T08:25:34.388592Z","shell.execute_reply.started":"2024-05-29T08:25:34.388300Z","shell.execute_reply":"2024-05-29T08:25:34.388323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.390855Z","iopub.status.idle":"2024-05-29T08:25:34.391473Z","shell.execute_reply.started":"2024-05-29T08:25:34.391186Z","shell.execute_reply":"2024-05-29T08:25:34.391211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.393163Z","iopub.status.idle":"2024-05-29T08:25:34.393739Z","shell.execute_reply.started":"2024-05-29T08:25:34.393431Z","shell.execute_reply":"2024-05-29T08:25:34.393462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:25:34.395621Z","iopub.status.idle":"2024-05-29T08:25:34.396182Z","shell.execute_reply.started":"2024-05-29T08:25:34.395885Z","shell.execute_reply":"2024-05-29T08:25:34.395910Z"},"trusted":true},"execution_count":null,"outputs":[]}]}