{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2560015,"sourceType":"datasetVersion","datasetId":1549969}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T16:14:20.885675Z","iopub.execute_input":"2024-05-29T16:14:20.885947Z","iopub.status.idle":"2024-05-29T16:14:21.255683Z","shell.execute_reply.started":"2024-05-29T16:14:20.885922Z","shell.execute_reply":"2024-05-29T16:14:21.254715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_train.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntest_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_test.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.256797Z","iopub.execute_input":"2024-05-29T16:14:21.257267Z","iopub.status.idle":"2024-05-29T16:14:21.295059Z","shell.execute_reply.started":"2024-05-29T16:14:21.257232Z","shell.execute_reply":"2024-05-29T16:14:21.294104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data = pd.concat([train_data, test_data])\nfull_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.296263Z","iopub.execute_input":"2024-05-29T16:14:21.296552Z","iopub.status.idle":"2024-05-29T16:14:21.306194Z","shell.execute_reply.started":"2024-05-29T16:14:21.296526Z","shell.execute_reply":"2024-05-29T16:14:21.305259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.308839Z","iopub.execute_input":"2024-05-29T16:14:21.309753Z","iopub.status.idle":"2024-05-29T16:14:21.324077Z","shell.execute_reply.started":"2024-05-29T16:14:21.309725Z","shell.execute_reply":"2024-05-29T16:14:21.323115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.325221Z","iopub.execute_input":"2024-05-29T16:14:21.325542Z","iopub.status.idle":"2024-05-29T16:14:21.796962Z","shell.execute_reply.started":"2024-05-29T16:14:21.325504Z","shell.execute_reply":"2024-05-29T16:14:21.796121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values_normalized = train['intent'].value_counts(normalize=True)\nprint(unique_values_normalized*100)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.798145Z","iopub.execute_input":"2024-05-29T16:14:21.798492Z","iopub.status.idle":"2024-05-29T16:14:21.808180Z","shell.execute_reply.started":"2024-05-29T16:14:21.798463Z","shell.execute_reply":"2024-05-29T16:14:21.807228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_values_normalized2 = test['intent'].value_counts(normalize=True)\nprint(unique_values_normalized2*100)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.809312Z","iopub.execute_input":"2024-05-29T16:14:21.809589Z","iopub.status.idle":"2024-05-29T16:14:21.821400Z","shell.execute_reply.started":"2024-05-29T16:14:21.809565Z","shell.execute_reply":"2024-05-29T16:14:21.820458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.822460Z","iopub.execute_input":"2024-05-29T16:14:21.822800Z","iopub.status.idle":"2024-05-29T16:14:21.836313Z","shell.execute_reply.started":"2024-05-29T16:14:21.822758Z","shell.execute_reply":"2024-05-29T16:14:21.835401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:21.837409Z","iopub.execute_input":"2024-05-29T16:14:21.837728Z","iopub.status.idle":"2024-05-29T16:14:24.613245Z","shell.execute_reply.started":"2024-05-29T16:14:21.837694Z","shell.execute_reply":"2024-05-29T16:14:24.612438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание токенизатора BERT\n# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:24.614356Z","iopub.execute_input":"2024-05-29T16:14:24.614784Z","iopub.status.idle":"2024-05-29T16:14:24.619035Z","shell.execute_reply.started":"2024-05-29T16:14:24.614759Z","shell.execute_reply":"2024-05-29T16:14:24.617968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\ntokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:24.620280Z","iopub.execute_input":"2024-05-29T16:14:24.620637Z","iopub.status.idle":"2024-05-29T16:14:25.182886Z","shell.execute_reply.started":"2024-05-29T16:14:24.620613Z","shell.execute_reply":"2024-05-29T16:14:25.182028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразование текста в токены\ninput_texts = train['text'].values.tolist()  # Преобразуйте тексты в список\ninput_ids = tokenizer.batch_encode_plus(input_texts, add_special_tokens=True, padding=True, truncation=True, max_length=64, return_tensors='pt')['input_ids']\n# labels = torch.tensor(train_data['intent'].values)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:25.183829Z","iopub.execute_input":"2024-05-29T16:14:25.184102Z","iopub.status.idle":"2024-05-29T16:14:25.876989Z","shell.execute_reply.started":"2024-05-29T16:14:25.184078Z","shell.execute_reply":"2024-05-29T16:14:25.875865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразование меток в числовой формат\nunique_intents = train['intent'].unique().tolist()\nintent_mapping = {intent: i for i, intent in enumerate(unique_intents)}\ntrain_labels = [intent_mapping[intent] for intent in train['intent']]\ntest_labels = [intent_mapping[intent] for intent in test['intent']]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:25.882756Z","iopub.execute_input":"2024-05-29T16:14:25.883291Z","iopub.status.idle":"2024-05-29T16:14:25.895398Z","shell.execute_reply.started":"2024-05-29T16:14:25.883262Z","shell.execute_reply":"2024-05-29T16:14:25.894526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import BertForSequenceClassification, AdamW","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:25.896564Z","iopub.execute_input":"2024-05-29T16:14:25.896881Z","iopub.status.idle":"2024-05-29T16:14:26.619584Z","shell.execute_reply.started":"2024-05-29T16:14:25.896857Z","shell.execute_reply":"2024-05-29T16:14:26.618748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Загрузка предобученной модели BERT\n#model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(train_data['intent'].unique()))\n\n#ruberttiny\n# model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n\nmodel = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\", num_labels=len(unique_intents))\n\n\n# Определение оптимизатора\noptimizer = AdamW(model.parameters(), lr=1e-3)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# # Преобразование текста в токены и создание маски внимания\n# input_ids = tokenizer.encode(train_data['text'].values, add_special_tokens=True, padding=True, truncation=True, max_length=64, return_tensors='pt')\n# #labels = torch.tensor(train_data['intent'].values)\n\n# Преобразование текста в токены и создание маски внимания\nencoding = tokenizer.batch_encode_plus(\n    train['text'].values.tolist(),  # Преобразуйте тексты в список\n    add_special_tokens=True,\n    padding=True,\n    truncation=True,\n    max_length=64,\n    return_tensors='pt'\n)\ninput_ids = encoding['input_ids']\nattention_mask = encoding['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:26.620711Z","iopub.execute_input":"2024-05-29T16:14:26.621144Z","iopub.status.idle":"2024-05-29T16:14:27.706685Z","shell.execute_reply.started":"2024-05-29T16:14:26.621117Z","shell.execute_reply":"2024-05-29T16:14:27.705838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_loss(train_losses, val_losses, n_epoches):\n#     plt.plot(loss_values)\n#     plt.xlabel('Epoch')\n#     plt.ylabel('Loss')\n#     plt.title('Training Loss')\n#     plt.show()\n    \n    # Построение графика потерь\n    plt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\n    plt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:27.707885Z","iopub.execute_input":"2024-05-29T16:14:27.708190Z","iopub.status.idle":"2024-05-29T16:14:27.714656Z","shell.execute_reply.started":"2024-05-29T16:14:27.708164Z","shell.execute_reply":"2024-05-29T16:14:27.713723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass IntentClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = str(self.texts[item])\n        label = self.labels[item]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Создание DataLoader\ndef create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n    ds = IntentClassificationDataset(\n        texts=texts,\n        labels=labels,\n        tokenizer=tokenizer,\n        max_len=max_len\n    )\n\n    return DataLoader(\n        ds,\n        batch_size=batch_size\n    )\n\n# Использование DataLoader в вашем коде\nbatch_size = 8 # 16\nmax_len = 64\ntrain_data_loader = create_data_loader(train['text'].values.tolist(), train_labels, tokenizer, max_len, batch_size)\ntest_data_loader = create_data_loader(test['text'].values.tolist(), test_labels, tokenizer, max_len, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:27.715932Z","iopub.execute_input":"2024-05-29T16:14:27.716234Z","iopub.status.idle":"2024-05-29T16:14:27.728636Z","shell.execute_reply.started":"2024-05-29T16:14:27.716196Z","shell.execute_reply":"2024-05-29T16:14:27.727738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(next(iter(train_data_loader)))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:27.729771Z","iopub.execute_input":"2024-05-29T16:14:27.730054Z","iopub.status.idle":"2024-05-29T16:14:27.742016Z","shell.execute_reply.started":"2024-05-29T16:14:27.730030Z","shell.execute_reply":"2024-05-29T16:14:27.740997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:27.743226Z","iopub.execute_input":"2024-05-29T16:14:27.743656Z","iopub.status.idle":"2024-05-29T16:14:27.752281Z","shell.execute_reply.started":"2024-05-29T16:14:27.743622Z","shell.execute_reply":"2024-05-29T16:14:27.751349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train bert","metadata":{}},{"cell_type":"code","source":"# # Количество эпох\n# epochs = 5\n\n# # Список для хранения значений потерь на каждой эпохе\n# loss_values = []\n# best_loss = float('inf')\n# best_acc = 0.8\n\n# for epoch in range(epochs):\n#     model.train()\n#     total_loss = 0\n\n#     # Используйте tqdm для отображения прогресса\n#     for batch in tqdm(train_data_loader, desc=f\"Epoch {epoch+1}\"):\n#         optimizer.zero_grad()\n#         input_ids = batch['input_ids']\n#         attention_mask = batch['attention_mask']\n#         labels = batch['labels']\n\n#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#         loss = outputs.loss\n#         total_loss += loss.item()\n#         loss.backward()\n#         optimizer.step()\n\n#     avg_train_loss = total_loss / len(train_data_loader)\n#     loss_values.append(avg_train_loss)\n\n#     print(f\"Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n\n#     model.eval()\n#     predictions , true_labels = [], []\n\n#     for batch in tqdm(test_data_loader, desc=f\"Validation Epoch {epoch+1}\"):\n#         with torch.no_grad():\n#             input_ids = batch['input_ids']\n#             attention_mask = batch['attention_mask']\n#             labels = batch['labels']\n\n#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#             logits = outputs.logits\n#             logits = logits.detach().cpu().numpy()\n#             label_ids = labels.to('cpu').numpy()\n            \n#             print(logits.shape)\n#             predictions.extend(np.argmax(logits, axis=1).flatten())\n#             true_labels.extend(label_ids.flatten())\n\n#     acc = accuracy_score(true_labels, predictions)\n#     rec = recall_score(true_labels, predictions, average='weighted')\n#     f1 = f1_score(true_labels, predictions, average='weighted')\n\n#     print(f\"Accuracy: {acc:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n\n#     # Ранняя остановка по потерям на валидации\n#     if avg_train_loss > best_loss:\n#         print(\"Early stopping due to increase in validation loss\")\n#         break\n\n#     # Ранняя остановка по точности на валидации\n#     if acc >= best_acc:\n#         print(\"Early stopping due to reaching target accuracy\")\n#         break\n\n#     best_loss = avg_train_loss\n\n# plot_loss(loss_values)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-29T16:14:27.753763Z","iopub.execute_input":"2024-05-29T16:14:27.754109Z","iopub.status.idle":"2024-05-29T16:14:27.764178Z","shell.execute_reply.started":"2024-05-29T16:14:27.754078Z","shell.execute_reply":"2024-05-29T16:14:27.763321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Train rubert tiny 2","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support\n\n# tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n# model = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\")\n\n# Количество эпох\nepochs = 10\n\ntrain_losses = []\nval_losses = []\n\n# Список для хранения значений потерь на каждой эпохе\nloss_values = []\nbest_loss = float('inf')\nbest_acc = 0.98\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    val_loss = 0\n    # Используйте tqdm для отображения прогресса\n    for batch in tqdm(train_data_loader, desc=f\"Epoch {epoch+1}\"):\n        optimizer.zero_grad()\n        # Move tensors to device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        train_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n\n    avg_train_loss = train_loss / len(train_data_loader)\n    loss_values.append(avg_train_loss)\n\n    print(f\"Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n\n    model.eval()\n    predictions, true_labels = [], []\n\n    for batch in tqdm(test_data_loader, desc=f\"Validation Epoch {epoch+1}\"):\n        with torch.no_grad():\n            # Move tensors to device\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n            val_loss += outputs.loss.item()\n            logits = outputs.logits\n            logits = logits.detach().cpu().numpy()\n            label_ids = labels.to('cpu').numpy()\n\n            predictions.extend(np.argmax(logits, axis=1).flatten())\n            true_labels.extend(label_ids.flatten())\n\n    avg_val_loss = val_loss / len(test_data_loader)\n    print(\"Balanced acc:\", balanced_accuracy_score(true_labels, predictions))\n    print(\"Weighted precision, recall, fscore:\", precision_recall_fscore_support(true_labels, predictions, average='weighted'))\n\n    best_loss = avg_train_loss\n\n    train_losses.append(avg_train_loss)\n    val_losses.append(avg_val_loss)\n\n# Plotting loss graph\ndef plot_loss(train_losses, val_losses, n_epochs):\n    import matplotlib.pyplot as plt\n\n    epochs = range(1, n_epochs + 1)\n    plt.plot(epochs, train_losses, 'b', label='Training loss')\n    plt.plot(epochs, val_losses, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\nplot_loss(train_losses, val_losses, epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:14:27.766188Z","iopub.execute_input":"2024-05-29T16:14:27.766485Z","iopub.status.idle":"2024-05-29T16:17:58.515581Z","shell.execute_reply.started":"2024-05-29T16:14:27.766461Z","shell.execute_reply":"2024-05-29T16:17:58.514623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import BertForSequenceClassification\n\n# # tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n# # model = BertForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny2\")\n\n# # Количество эпох\n# epochs = 7\n\n# train_losses = []\n# val_losses = []\n\n# # Список для хранения значений потерь на каждой эпохе\n# loss_values = []\n# best_loss = float('inf')\n# best_acc = 0.98\n\n# for epoch in range(epochs):\n#     model.train()\n# #     total_loss = 0\n#     train_loss = 0\n#     val_loss = 0\n#     # Используйте tqdm для отображения прогресса\n#     for batch in tqdm(train_data_loader, desc=f\"Epoch {epoch+1}\"):\n#         optimizer.zero_grad()\n# #         input_ids = batch['input_ids']\n# #         attention_mask = batch['attention_mask']\n# #         labels = batch['labels']\n#         # Move tensors to device\n#         input_ids = batch['input_ids'].to(device)\n#         attention_mask = batch['attention_mask'].to(device)\n#         labels = batch['labels'].to(device)\n\n\n#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#         loss = outputs.loss\n#         # total_loss += loss.item()\n#         train_loss += loss.item()\n#         loss.backward()\n#         optimizer.step()\n\n#     avg_train_loss = total_loss / len(train_data_loader)\n#     loss_values.append(avg_train_loss)\n\n#     print(f\"Epoch: {epoch+1}, Train Loss: {avg_train_loss:.4f}\")\n\n#     model.eval()\n#     predictions , true_labels = [], []\n\n#     for batch in tqdm(test_data_loader, desc=f\"Validation Epoch {epoch+1}\"):\n#         with torch.no_grad():\n# #             input_ids = batch['input_ids']\n# #             attention_mask = batch['attention_mask']\n# #             labels = batch['labels']\n#             # Move tensors to device\n#             input_ids = batch['input_ids'].to(device)\n#             attention_mask = batch['attention_mask'].to(device)\n#             labels = batch['labels'].to(device)\n\n\n#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n#             logits = outputs.logits\n#             logits = logits.detach().cpu().numpy()\n#             label_ids = labels.to('cpu').numpy()\n            \n#             val_loss += loss.item()\n            \n#             # print(logits.shape)\n#             predictions.extend(np.argmax(logits, axis=1).flatten())\n#             true_labels.extend(label_ids.flatten())\n\n# #     acc = accuracy_score(true_labels, predictions)\n# #     rec = recall_score(true_labels, predictions, average='weighted')\n# #     f1 = f1_score(true_labels, predictions, average='weighted')\n\n# #     print(f\"Accuracy: {acc:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\")\n#     print(\"Balanced acc:\", balanced_accuracy_score(true_labels, predictions))\n#     print(\"Weighted precision, recall, fscore:\", precision_recall_fscore_support(true_labels, predictions, average='weighted'))\n\n# #     # Ранняя остановка по потерям на валидации\n# #     if avg_train_loss > best_loss:\n# #         print(\"Early stopping due to increase in validation loss\")\n# #         break\n\n# #     # Ранняя остановка по точности на валидации\n# #     if acc >= best_acc:\n# #         print(\"Early stopping due to reaching target accuracy\")\n# #         break\n\n#     best_loss = avg_train_loss\n    \n#     train_loss /= len(train_loader)\n#     val_loss /= len(test_loader)\n#     train_losses.append(train_loss)\n#     val_losses.append(val_loss)\n\n\n# plot_loss(val_loss, train_loss, n_epoches)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:17:58.517064Z","iopub.execute_input":"2024-05-29T16:17:58.517456Z","iopub.status.idle":"2024-05-29T16:17:58.525656Z","shell.execute_reply.started":"2024-05-29T16:17:58.517419Z","shell.execute_reply":"2024-05-29T16:17:58.524596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport timeit","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:17:58.527059Z","iopub.execute_input":"2024-05-29T16:17:58.527569Z","iopub.status.idle":"2024-05-29T16:17:58.584296Z","shell.execute_reply.started":"2024-05-29T16:17:58.527534Z","shell.execute_reply":"2024-05-29T16:17:58.583415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Предсказание на тестовых данных\nmodel.eval()\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for batch in test_data_loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs.logits, dim=1)\n\n        predictions.extend(preds)\nend_test = timeit.default_timer()\npredicted_labels = [pred.item() for pred in predictions]\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:17:58.585276Z","iopub.execute_input":"2024-05-29T16:17:58.585543Z","iopub.status.idle":"2024-05-29T16:18:00.278531Z","shell.execute_reply.started":"2024-05-29T16:17:58.585519Z","shell.execute_reply":"2024-05-29T16:18:00.277580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(balanced_accuracy_score(test_labels, predicted_labels))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:18:00.280008Z","iopub.execute_input":"2024-05-29T16:18:00.280811Z","iopub.status.idle":"2024-05-29T16:18:00.284774Z","shell.execute_reply.started":"2024-05-29T16:18:00.280772Z","shell.execute_reply":"2024-05-29T16:18:00.283809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(balanced_accuracy_score(test_labels, predicted_labels))\nprint(precision_recall_fscore_support(test_labels, predicted_labels, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:18:00.286006Z","iopub.execute_input":"2024-05-29T16:18:00.286346Z","iopub.status.idle":"2024-05-29T16:18:00.306295Z","shell.execute_reply.started":"2024-05-29T16:18:00.286314Z","shell.execute_reply":"2024-05-29T16:18:00.305454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построение confusion matrix\ncm = confusion_matrix(test_labels, predicted_labels)\nprint(f'Confusion Matrix: \\n{cm}')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:18:00.307571Z","iopub.execute_input":"2024-05-29T16:18:00.308177Z","iopub.status.idle":"2024-05-29T16:18:00.320828Z","shell.execute_reply.started":"2024-05-29T16:18:00.308145Z","shell.execute_reply":"2024-05-29T16:18:00.317802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Визуализация матрицы ошибок с использованием seaborn\n# plt.figure(figsize=(20, 20))\n# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=set(test_labels), yticklabels=set(predicted_labels))\n# plt.xlabel('Предсказанный класс')\n# plt.ylabel('Истинный класс')\n# plt.title('Матрица ошибок')\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T16:18:00.322882Z","iopub.execute_input":"2024-05-29T16:18:00.323340Z","iopub.status.idle":"2024-05-29T16:18:00.328528Z","shell.execute_reply.started":"2024-05-29T16:18:00.323301Z","shell.execute_reply":"2024-05-29T16:18:00.327307Z"},"trusted":true},"execution_count":null,"outputs":[]}]}