{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2560015,"sourceType":"datasetVersion","datasetId":1549969}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-01T16:11:46.436502Z","iopub.execute_input":"2024-06-01T16:11:46.437405Z","iopub.status.idle":"2024-06-01T16:11:47.354634Z","shell.execute_reply.started":"2024-06-01T16:11:46.437372Z","shell.execute_reply":"2024-06-01T16:11:47.353729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn\nimport timeit","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:47.356255Z","iopub.execute_input":"2024-06-01T16:11:47.356672Z","iopub.status.idle":"2024-06-01T16:11:52.687771Z","shell.execute_reply.started":"2024-06-01T16:11:47.356646Z","shell.execute_reply":"2024-06-01T16:11:52.686918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import Dataset \nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.688860Z","iopub.execute_input":"2024-06-01T16:11:52.689250Z","iopub.status.idle":"2024-06-01T16:11:52.855860Z","shell.execute_reply.started":"2024-06-01T16:11:52.689226Z","shell.execute_reply":"2024-06-01T16:11:52.854944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.858265Z","iopub.execute_input":"2024-06-01T16:11:52.858562Z","iopub.status.idle":"2024-06-01T16:11:52.863479Z","shell.execute_reply.started":"2024-06-01T16:11:52.858538Z","shell.execute_reply":"2024-06-01T16:11:52.862511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_train.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntest_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_test.tsv',delimiter='\\t',encoding=\"utf-8\",names=['text', 'intent'])\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.864709Z","iopub.execute_input":"2024-06-01T16:11:52.865035Z","iopub.status.idle":"2024-06-01T16:11:52.934164Z","shell.execute_reply.started":"2024-06-01T16:11:52.865005Z","shell.execute_reply":"2024-06-01T16:11:52.933287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_data = pd.concat([train_data, test_data])\nfull_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.935224Z","iopub.execute_input":"2024-06-01T16:11:52.935479Z","iopub.status.idle":"2024-06-01T16:11:52.946351Z","shell.execute_reply.started":"2024-06-01T16:11:52.935458Z","shell.execute_reply":"2024-06-01T16:11:52.945300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\nunique_values_normalized = train['intent'].value_counts(normalize=True)\nprint(unique_values_normalized*100)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.947671Z","iopub.execute_input":"2024-06-01T16:11:52.948008Z","iopub.status.idle":"2024-06-01T16:11:52.971626Z","shell.execute_reply.started":"2024-06-01T16:11:52.947970Z","shell.execute_reply":"2024-06-01T16:11:52.970801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.972673Z","iopub.execute_input":"2024-06-01T16:11:52.972910Z","iopub.status.idle":"2024-06-01T16:11:52.978259Z","shell.execute_reply.started":"2024-06-01T16:11:52.972889Z","shell.execute_reply":"2024-06-01T16:11:52.977376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Добавление дополнительного измерения\n#         print(f'x shape: {x.shape}')\n        lstm_out, _ = self.lstm(x)\n        out = self.fc(lstm_out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.979359Z","iopub.execute_input":"2024-06-01T16:11:52.979647Z","iopub.status.idle":"2024-06-01T16:11:52.989549Z","shell.execute_reply.started":"2024-06-01T16:11:52.979625Z","shell.execute_reply":"2024-06-01T16:11:52.988511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !\nfrom sklearn.preprocessing import LabelEncoder\n\n# Создание LabelEncoder\nle = LabelEncoder()\n\n# Подготовка данных\nfull_data = pd.concat([train_data, test_data])\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n# # Токенизация и преобразование в TF-IDF\n# tokenizer = word_tokenize\n# vectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\n\n# train_texts = vectorizer.fit_transform(train['text']).toarray()\n# test_texts = vectorizer.transform(test['text']).toarray()\n\n# # Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\n# train_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\n# test_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:52.990959Z","iopub.execute_input":"2024-06-01T16:11:52.991741Z","iopub.status.idle":"2024-06-01T16:11:53.012806Z","shell.execute_reply.started":"2024-06-01T16:11:52.991706Z","shell.execute_reply":"2024-06-01T16:11:53.011772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Токенизация и преобразование в TF-IDF\ntokenizer = word_tokenize\nvectorizer = TfidfVectorizer(tokenizer=tokenizer)\n\ntrain_texts = vectorizer.fit_transform(train['text']).toarray()\ntest_texts = vectorizer.transform(test['text']).toarray()\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\ntest_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:53.017149Z","iopub.execute_input":"2024-06-01T16:11:53.017428Z","iopub.status.idle":"2024-06-01T16:11:55.091281Z","shell.execute_reply.started":"2024-06-01T16:11:53.017404Z","shell.execute_reply":"2024-06-01T16:11:55.090268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Подготовка данных\n# full_data = pd.concat([train_data, test_data])\n# train, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# le = LabelEncoder()\n# train_labels = le.fit_transform(train['intent'])\n# test_labels = le.transform(test['intent'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:55.092355Z","iopub.execute_input":"2024-06-01T16:11:55.092631Z","iopub.status.idle":"2024-06-01T16:11:55.098785Z","shell.execute_reply.started":"2024-06-01T16:11:55.092608Z","shell.execute_reply":"2024-06-01T16:11:55.097851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_texts.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25\n\nfor epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for i, (texts, labels) in enumerate(tqdm(train_loader)):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for i, (texts, labels) in enumerate(tqdm(test_loader)):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:11:55.100076Z","iopub.execute_input":"2024-06-01T16:11:55.100332Z","iopub.status.idle":"2024-06-01T16:12:25.693341Z","shell.execute_reply.started":"2024-06-01T16:11:55.100311Z","shell.execute_reply":"2024-06-01T16:12:25.692400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(balanced_accuracy_score(test_labels, predictions))\n# print(precision_recall_fscore_support(test_labels, predictions, average = 'weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:25.694554Z","iopub.execute_input":"2024-06-01T16:12:25.695052Z","iopub.status.idle":"2024-06-01T16:12:25.699998Z","shell.execute_reply.started":"2024-06-01T16:12:25.695024Z","shell.execute_reply":"2024-06-01T16:12:25.698940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(balanced_accuracy_score(test_labels, predictions))\nprint(precision_recall_fscore_support(test_labels, predictions, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:25.701298Z","iopub.execute_input":"2024-06-01T16:12:25.701714Z","iopub.status.idle":"2024-06-01T16:12:25.846356Z","shell.execute_reply.started":"2024-06-01T16:12:25.701674Z","shell.execute_reply":"2024-06-01T16:12:25.845374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение входных данных, истинных меток и предсказаний в DataFrame\nresults_df = pd.DataFrame({\n    'Input': test['text'],\n    'True Label': test['intent'],\n    'Predicted Label': predicted_intents\n})\n\n# Сохранение DataFrame в CSV файл\nresults_df.to_csv('model_predictions.csv', index=False)\n\n# Вывод первых нескольких строк для проверки\nprint(results_df.head())\nprint(results_df[results_df['True Label']!=results_df['Predicted Label']])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:25.847926Z","iopub.execute_input":"2024-06-01T16:12:25.848286Z","iopub.status.idle":"2024-06-01T16:12:25.879815Z","shell.execute_reply.started":"2024-06-01T16:12:25.848253Z","shell.execute_reply":"2024-06-01T16:12:25.878903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mini-LM","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:25.880753Z","iopub.execute_input":"2024-06-01T16:12:25.880993Z","iopub.status.idle":"2024-06-01T16:12:26.349180Z","shell.execute_reply.started":"2024-06-01T16:12:25.880972Z","shell.execute_reply":"2024-06-01T16:12:26.348335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:26.350304Z","iopub.execute_input":"2024-06-01T16:12:26.350633Z","iopub.status.idle":"2024-06-01T16:12:26.356553Z","shell.execute_reply.started":"2024-06-01T16:12:26.350597Z","shell.execute_reply":"2024-06-01T16:12:26.355521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание пользовательского Dataset класса\nclass TextDataset(Dataset):\n    def __init__(self, embeddings, labels):\n        self.embeddings = embeddings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.embeddings[idx], self.labels[idx]\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:26.357839Z","iopub.execute_input":"2024-06-01T16:12:26.358093Z","iopub.status.idle":"2024-06-01T16:12:26.365577Z","shell.execute_reply.started":"2024-06-01T16:12:26.358071Z","shell.execute_reply":"2024-06-01T16:12:26.364646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Определение модели LSTM\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(LSTMClassifier, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        _, (hn, _) = self.lstm(x.unsqueeze(1))\n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:26.367172Z","iopub.execute_input":"2024-06-01T16:12:26.368038Z","iopub.status.idle":"2024-06-01T16:12:26.378192Z","shell.execute_reply.started":"2024-06-01T16:12:26.368006Z","shell.execute_reply":"2024-06-01T16:12:26.377261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n\n# Load your dataset\ntrain_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_train.tsv', delimiter='\\t', encoding=\"utf-8\", names=['text', 'intent'])\ntest_data = pd.read_csv('../input/qa-intents-dataset-university-domain/dataset_test.tsv', delimiter='\\t', encoding=\"utf-8\", names=['text', 'intent'])\nfull_data = pd.concat([train_data, test_data])\n\n# Split the data into train and test sets\ntrain, test = train_test_split(full_data, test_size=0.2, random_state=42)\n\n# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Extract embeddings\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).pooler_output\n    test_embeddings = model(**test_encodings).pooler_output\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:12:26.381394Z","iopub.execute_input":"2024-06-01T16:12:26.381711Z","iopub.status.idle":"2024-06-01T16:16:58.723798Z","shell.execute_reply.started":"2024-06-01T16:12:26.381687Z","shell.execute_reply":"2024-06-01T16:16:58.721793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25\n\nfor epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:16:58.725063Z","iopub.status.idle":"2024-06-01T16:16:58.725862Z","shell.execute_reply.started":"2024-06-01T16:16:58.725658Z","shell.execute_reply":"2024-06-01T16:16:58.725677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:16:58.726952Z","iopub.status.idle":"2024-06-01T16:16:58.727344Z","shell.execute_reply.started":"2024-06-01T16:16:58.727173Z","shell.execute_reply":"2024-06-01T16:16:58.727188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:16:58.728580Z","iopub.status.idle":"2024-06-01T16:16:58.728961Z","shell.execute_reply.started":"2024-06-01T16:16:58.728794Z","shell.execute_reply":"2024-06-01T16:16:58.728809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:16:58.730154Z","iopub.status.idle":"2024-06-01T16:16:58.730507Z","shell.execute_reply.started":"2024-06-01T16:16:58.730342Z","shell.execute_reply":"2024-06-01T16:16:58.730357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение входных данных, истинных меток и предсказаний в DataFrame\nresults_df = pd.DataFrame({\n    'Input': test['text'],\n    'True Label': test['intent'],\n    'Predicted Label': predicted_intents\n})\n\n# Сохранение DataFrame в CSV файл\nresults_df.to_csv('model_predictions.csv', index=False)\n\n# Вывод первых нескольких строк для проверки\nprint(results_df.head())\nprint(results_df[results_df['True Label']!=results_df['Predicted Label']])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:16:58.731391Z","iopub.status.idle":"2024-06-01T16:16:58.731762Z","shell.execute_reply.started":"2024-06-01T16:16:58.731566Z","shell.execute_reply":"2024-06-01T16:16:58.731580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"M-USE","metadata":{}},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")\nmodel = AutoModel.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:17:08.243361Z","iopub.execute_input":"2024-06-01T16:17:08.243755Z","iopub.status.idle":"2024-06-01T16:17:12.811490Z","shell.execute_reply.started":"2024-06-01T16:17:08.243717Z","shell.execute_reply":"2024-06-01T16:17:12.810596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Извлечение эмбеддингов\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).last_hidden_state.mean(dim=1)\n    test_embeddings = model(**test_encodings).last_hidden_state.mean(dim=1)\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:17:12.813373Z","iopub.execute_input":"2024-06-01T16:17:12.813742Z","iopub.status.idle":"2024-06-01T16:22:06.456298Z","shell.execute_reply.started":"2024-06-01T16:17:12.813709Z","shell.execute_reply":"2024-06-01T16:22:06.455502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:06.457492Z","iopub.execute_input":"2024-06-01T16:22:06.457842Z","iopub.status.idle":"2024-06-01T16:22:06.503038Z","shell.execute_reply.started":"2024-06-01T16:22:06.457810Z","shell.execute_reply":"2024-06-01T16:22:06.502246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:06.505161Z","iopub.execute_input":"2024-06-01T16:22:06.505459Z","iopub.status.idle":"2024-06-01T16:22:28.024650Z","shell.execute_reply.started":"2024-06-01T16:22:06.505433Z","shell.execute_reply":"2024-06-01T16:22:28.023756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:28.025861Z","iopub.execute_input":"2024-06-01T16:22:28.026122Z","iopub.status.idle":"2024-06-01T16:22:28.223025Z","shell.execute_reply.started":"2024-06-01T16:22:28.026100Z","shell.execute_reply":"2024-06-01T16:22:28.222070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:28.224261Z","iopub.execute_input":"2024-06-01T16:22:28.224534Z","iopub.status.idle":"2024-06-01T16:22:28.228914Z","shell.execute_reply.started":"2024-06-01T16:22:28.224510Z","shell.execute_reply":"2024-06-01T16:22:28.228074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:28.229995Z","iopub.execute_input":"2024-06-01T16:22:28.230277Z","iopub.status.idle":"2024-06-01T16:22:28.370731Z","shell.execute_reply.started":"2024-06-01T16:22:28.230245Z","shell.execute_reply":"2024-06-01T16:22:28.369652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение входных данных, истинных меток и предсказаний в DataFrame\nresults_df = pd.DataFrame({\n    'Input': test['text'],\n    'True Label': test['intent'],\n    'Predicted Label': predicted_intents\n})\n\n# Сохранение DataFrame в CSV файл\nresults_df.to_csv('model_predictions.csv', index=False)\n\n\n# print(results_df[results_df['True Label']!=results_df['Predicted Label']])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:22:28.372120Z","iopub.execute_input":"2024-06-01T16:22:28.372489Z","iopub.status.idle":"2024-06-01T16:22:28.392819Z","shell.execute_reply.started":"2024-06-01T16:22:28.372451Z","shell.execute_reply":"2024-06-01T16:22:28.391882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вывод первых нескольких строк для проверки\n# print(results_df.head(25))\nprint(results_df[51:75])\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:52:50.613358Z","iopub.execute_input":"2024-06-01T16:52:50.614083Z","iopub.status.idle":"2024-06-01T16:52:50.621878Z","shell.execute_reply.started":"2024-06-01T16:52:50.614049Z","shell.execute_reply":"2024-06-01T16:52:50.620929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_df[results_df['True Label']!=results_df['Predicted Label']][41:60])","metadata":{"execution":{"iopub.status.busy":"2024-06-01T16:57:30.426714Z","iopub.execute_input":"2024-06-01T16:57:30.427391Z","iopub.status.idle":"2024-06-01T16:57:30.436894Z","shell.execute_reply.started":"2024-06-01T16:57:30.427361Z","shell.execute_reply":"2024-06-01T16:57:30.435873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_df[results_df['Input'] == 'как сдать экзамены']) ","metadata":{"execution":{"iopub.status.busy":"2024-06-01T17:03:35.697965Z","iopub.execute_input":"2024-06-01T17:03:35.698342Z","iopub.status.idle":"2024-06-01T17:03:35.706832Z","shell.execute_reply.started":"2024-06-01T17:03:35.698313Z","shell.execute_reply":"2024-06-01T17:03:35.705884Z"},"trusted":true},"execution_count":null,"outputs":[]}]}