{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":585165,"sourceType":"datasetVersion","datasetId":284285}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-30T14:31:57.304034Z","iopub.execute_input":"2024-05-30T14:31:57.304578Z","iopub.status.idle":"2024-05-30T14:31:58.634324Z","shell.execute_reply.started":"2024-05-30T14:31:57.304529Z","shell.execute_reply":"2024-05-30T14:31:58.632538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, confusion_matrix, accuracy_score\nimport seaborn as sns\nimport timeit\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:34:42.453620Z","iopub.execute_input":"2024-05-30T14:34:42.454183Z","iopub.status.idle":"2024-05-30T14:34:42.468458Z","shell.execute_reply.started":"2024-05-30T14:34:42.454144Z","shell.execute_reply":"2024-05-30T14:34:42.466830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Путь к файлу CSV\ndata_path = \"/kaggle/input/atis-airlinetravelinformationsystem/atis_intents.csv\"\n\n# Чтение данных из CSV-файла\ndata = pd.read_csv(data_path)\ndata = data.rename(columns={'atis_flight': 'intent', ' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning': 'text'})\nlost_intent = {'intent': 'atis_flight', 'text': 'i want to fly from boston at 838 am and arrive in denver at 1110 in the morning'}\ndata = pd.concat([data, pd.DataFrame([lost_intent])], ignore_index=True)\n\n# Find classes with only one sample\nclass_counts = data['intent'].value_counts()\nsingle_sample_classes = class_counts[class_counts == 1].index.tolist()\n\n# Separate single sample classes\nsingle_sample_data = data[data['intent'].isin(single_sample_classes)]\nmultiple_sample_data = data[~data['intent'].isin(single_sample_classes)]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:06.122122Z","iopub.execute_input":"2024-05-30T14:32:06.122805Z","iopub.status.idle":"2024-05-30T14:32:06.190837Z","shell.execute_reply.started":"2024-05-30T14:32:06.122762Z","shell.execute_reply":"2024-05-30T14:32:06.189259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform stratified split on multiple sample data\ntrain_multiple, test_multiple = train_test_split(multiple_sample_data, test_size=0.2, random_state=42, stratify=multiple_sample_data['intent'])\n\n# Add single sample data to both train and test sets to ensure all classes are present\ntrain = pd.concat([train_multiple, single_sample_data]).reset_index(drop=True)\ntest = pd.concat([test_multiple, single_sample_data]).reset_index(drop=True)\n\n# Ensure no duplicates in train and test sets\ntrain = train.drop_duplicates().reset_index(drop=True)\ntest = test.drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:06.194005Z","iopub.execute_input":"2024-05-30T14:32:06.194592Z","iopub.status.idle":"2024-05-30T14:32:06.229963Z","shell.execute_reply.started":"2024-05-30T14:32:06.194550Z","shell.execute_reply":"2024-05-30T14:32:06.228565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing classes and ensure all classes are present\ntrain_classes = set(train['intent'])\ntest_classes = set(test['intent'])\nall_classes = set(data['intent'])\n\n# Find missing classes in train and test sets\nmissing_train_classes = all_classes - train_classes\nmissing_test_classes = all_classes - test_classes\n\n# Add missing classes examples to train and test sets\nif missing_train_classes:\n    missing_train_data = data[data['intent'].isin(missing_train_classes)]\n    train = pd.concat([train, missing_train_data])\n    train = train.drop_duplicates().reset_index(drop=True)\n\nif missing_test_classes:\n    missing_test_data = data[data['intent'].isin(missing_test_classes)]\n    test = pd.concat([test, missing_test_data])\n    test = test.drop_duplicates().reset_index(drop=True)\n\n# Print unique value proportions\nunique_values_normalized = train['intent'].value_counts(normalize=True)\nunique_values_normalized_test = test['intent'].value_counts(normalize=True)\nunique_values_normalized_data = data['intent'].value_counts(normalize=True)\nprint(unique_values_normalized * 100, len(unique_values_normalized), len(unique_values_normalized_test),len(unique_values_normalized_data)) ","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:06.231793Z","iopub.execute_input":"2024-05-30T14:32:06.232312Z","iopub.status.idle":"2024-05-30T14:32:06.259148Z","shell.execute_reply.started":"2024-05-30T14:32:06.232253Z","shell.execute_reply":"2024-05-30T14:32:06.257774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразование меток в числовые значения\nle = LabelEncoder()\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n# Токенизация и преобразование в TF-IDF\ntokenizer = word_tokenize\nvectorizer = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\ntrain_texts = vectorizer.fit_transform(train['text']).toarray()\ntest_texts = vectorizer.transform(test['text']).toarray()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:06.260949Z","iopub.execute_input":"2024-05-30T14:32:06.261483Z","iopub.status.idle":"2024-05-30T14:32:07.395757Z","shell.execute_reply.started":"2024-05-30T14:32:06.261436Z","shell.execute_reply":"2024-05-30T14:32:07.394140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Определение датасета\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n    \n# Определение модели Bidirectional LSTM\nclass BidirectionalLSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Умножаем на 2 из-за двунаправленности\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Добавление дополнительного измерения\n        lstm_out, _ = self.lstm(x)\n        out = self.fc(lstm_out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:07.398119Z","iopub.execute_input":"2024-05-30T14:32:07.398710Z","iopub.status.idle":"2024-05-30T14:32:07.410864Z","shell.execute_reply.started":"2024-05-30T14:32:07.398639Z","shell.execute_reply":"2024-05-30T14:32:07.409191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\ntest_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:32:07.412983Z","iopub.execute_input":"2024-05-30T14:32:07.413530Z","iopub.status.idle":"2024-05-30T14:32:07.432040Z","shell.execute_reply.started":"2024-05-30T14:32:07.413481Z","shell.execute_reply":"2024-05-30T14:32:07.430469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Инициализация модели\nmodel = BidirectionalLSTMClassifier(input_dim=train_texts.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Настройка устройства\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\n# Определение функции потерь и оптимизатора\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Обучение модели\ntrain_losses = []\nval_losses = []\n\nn_epoches = 15","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:04.671626Z","iopub.execute_input":"2024-05-30T14:35:04.672157Z","iopub.status.idle":"2024-05-30T14:35:04.709742Z","shell.execute_reply.started":"2024-05-30T14:35:04.672116Z","shell.execute_reply":"2024-05-30T14:35:04.708028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:35:04.712769Z","iopub.execute_input":"2024-05-30T14:35:04.713218Z","iopub.status.idle":"2024-05-30T14:36:24.770126Z","shell.execute_reply.started":"2024-05-30T14:35:04.713180Z","shell.execute_reply":"2024-05-30T14:36:24.768675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for texts, labels in test_loader:\n        texts = texts.float().to(device)\n        outputs = model(texts)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy()) \nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\n\nprint(balanced_accuracy_score(test_labels, predictions))\nprint(precision_recall_fscore_support(test_labels, predictions, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:36:24.772801Z","iopub.execute_input":"2024-05-30T14:36:24.773229Z","iopub.status.idle":"2024-05-30T14:36:24.922790Z","shell.execute_reply.started":"2024-05-30T14:36:24.773190Z","shell.execute_reply":"2024-05-30T14:36:24.921627Z"},"trusted":true},"execution_count":null,"outputs":[]}]}