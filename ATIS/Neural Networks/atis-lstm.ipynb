{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":585165,"sourceType":"datasetVersion","datasetId":284285}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T08:19:45.551659Z","iopub.execute_input":"2024-05-29T08:19:45.552259Z","iopub.status.idle":"2024-05-29T08:19:45.594743Z","shell.execute_reply.started":"2024-05-29T08:19:45.552207Z","shell.execute_reply":"2024-05-29T08:19:45.593264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torch import nn\nimport timeit","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.597917Z","iopub.execute_input":"2024-05-29T08:19:45.598627Z","iopub.status.idle":"2024-05-29T08:19:45.606000Z","shell.execute_reply.started":"2024-05-29T08:19:45.598577Z","shell.execute_reply":"2024-05-29T08:19:45.604479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.607982Z","iopub.execute_input":"2024-05-29T08:19:45.608573Z","iopub.status.idle":"2024-05-29T08:19:45.625526Z","shell.execute_reply.started":"2024-05-29T08:19:45.608529Z","shell.execute_reply":"2024-05-29T08:19:45.624199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Путь к файлу CSV\ndata_path = \"/kaggle/input/atis-airlinetravelinformationsystem/atis_intents.csv\"\ntrain_data_path = \"/kaggle/input/atis-airlinetravelinformationsystem/atis_intents_train.csv\"\ntest_data_path = \"/kaggle/input/atis-airlinetravelinformationsystem/atis_intents_test.csv\"\n\n# Чтение данных из CSV-файлов\ndata = pd.read_csv(data_path)\ntrain_data = pd.read_csv(train_data_path)\ntest_data = pd.read_csv(test_data_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.627339Z","iopub.execute_input":"2024-05-29T08:19:45.627772Z","iopub.status.idle":"2024-05-29T08:19:45.674564Z","shell.execute_reply.started":"2024-05-29T08:19:45.627735Z","shell.execute_reply":"2024-05-29T08:19:45.673287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = data.rename(columns={'atis_flight': 'intent', ' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning': 'text'})\nlost_intent = {'intent': 'atis_flight', 'text': 'i want to fly from boston at 838 am and arrive in denver at 1110 in the morning'}\ndata = pd.concat([data, pd.DataFrame([lost_intent])], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.677704Z","iopub.execute_input":"2024-05-29T08:19:45.678176Z","iopub.status.idle":"2024-05-29T08:19:45.688008Z","shell.execute_reply.started":"2024-05-29T08:19:45.678137Z","shell.execute_reply":"2024-05-29T08:19:45.686059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find classes with only one sample\nclass_counts = data['intent'].value_counts()\nsingle_sample_classes = class_counts[class_counts == 1].index.tolist()\n\n# Separate single sample classes\nsingle_sample_data = data[data['intent'].isin(single_sample_classes)]\nmultiple_sample_data = data[~data['intent'].isin(single_sample_classes)]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.689802Z","iopub.execute_input":"2024-05-29T08:19:45.690293Z","iopub.status.idle":"2024-05-29T08:19:45.711158Z","shell.execute_reply.started":"2024-05-29T08:19:45.690251Z","shell.execute_reply":"2024-05-29T08:19:45.709607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, test = train_test_split(data, test_size=0.2, random_state=42, stratify=data['intent'])\n# Perform stratified split on multiple sample data\ntrain_multiple, test_multiple = train_test_split(multiple_sample_data, test_size=0.2, random_state=42, stratify=multiple_sample_data['intent'])\n\n# Add single sample data to both train and test sets to ensure all classes are present\ntrain = pd.concat([train_multiple, single_sample_data]).reset_index(drop=True)\ntest = pd.concat([test_multiple, single_sample_data]).reset_index(drop=True)\n\n# Ensure no duplicates in train and test sets\ntrain = train.drop_duplicates().reset_index(drop=True)\ntest = test.drop_duplicates().reset_index(drop=True)\n\nunique_values_normalized = train['intent'].value_counts(normalize=True)\nunique_values_normalized_test = test['intent'].value_counts(normalize=True)\nprint(unique_values_normalized*100, len(unique_values_normalized), len(unique_values_normalized_test))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.713071Z","iopub.execute_input":"2024-05-29T08:19:45.713723Z","iopub.status.idle":"2024-05-29T08:19:45.756757Z","shell.execute_reply.started":"2024-05-29T08:19:45.713616Z","shell.execute_reply":"2024-05-29T08:19:45.755044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing classes and ensure all classes are present\ntrain_classes = set(train['intent'])\ntest_classes = set(test['intent'])\nall_classes = set(data['intent'])\n\n# Find missing classes in train and test sets\nmissing_train_classes = all_classes - train_classes\nmissing_test_classes = all_classes - test_classes\n\n# Add missing classes examples to train and test sets\nif missing_train_classes:\n    missing_train_data = data[data['intent'].isin(missing_train_classes)]\n    train = pd.concat([train, missing_train_data])\n    train = train.drop_duplicates().reset_index(drop=True)\n\nif missing_test_classes:\n    missing_test_data = data[data['intent'].isin(missing_test_classes)]\n    test = pd.concat([test, missing_test_data])\n    test = test.drop_duplicates().reset_index(drop=True)\n\n# Print unique value proportions\nunique_values_normalized = train['intent'].value_counts(normalize=True)\nunique_values_normalized_test = test['intent'].value_counts(normalize=True)\nprint(unique_values_normalized * 100, len(unique_values_normalized), len(unique_values_normalized_test)) ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.759114Z","iopub.execute_input":"2024-05-29T08:19:45.759555Z","iopub.status.idle":"2024-05-29T08:19:45.779096Z","shell.execute_reply.started":"2024-05-29T08:19:45.759516Z","shell.execute_reply":"2024-05-29T08:19:45.777657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.781063Z","iopub.execute_input":"2024-05-29T08:19:45.781514Z","iopub.status.idle":"2024-05-29T08:19:45.789933Z","shell.execute_reply.started":"2024-05-29T08:19:45.781477Z","shell.execute_reply":"2024-05-29T08:19:45.788543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)  # Добавление дополнительного измерения\n#         print(f'x shape: {x.shape}')\n        lstm_out, _ = self.lstm(x)\n        out = self.fc(lstm_out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.792363Z","iopub.execute_input":"2024-05-29T08:19:45.792801Z","iopub.status.idle":"2024-05-29T08:19:45.811150Z","shell.execute_reply.started":"2024-05-29T08:19:45.792763Z","shell.execute_reply":"2024-05-29T08:19:45.809180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Создание LabelEncoder\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.813488Z","iopub.execute_input":"2024-05-29T08:19:45.814113Z","iopub.status.idle":"2024-05-29T08:19:45.829693Z","shell.execute_reply.started":"2024-05-29T08:19:45.814037Z","shell.execute_reply":"2024-05-29T08:19:45.828100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Токенизация и преобразование в TF-IDF\ntokenizer = word_tokenize\nvectorizer = TfidfVectorizer(tokenizer=tokenizer)\n\ntrain_texts = vectorizer.fit_transform(train['text']).toarray()\ntest_texts = vectorizer.transform(test['text']).toarray()\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(torch.from_numpy(train_texts), train_labels)\ntest_dataset = TextDataset(torch.from_numpy(test_texts), test_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:45.831604Z","iopub.execute_input":"2024-05-29T08:19:45.832169Z","iopub.status.idle":"2024-05-29T08:19:46.654738Z","shell.execute_reply.started":"2024-05-29T08:19:45.832110Z","shell.execute_reply":"2024-05-29T08:19:46.653459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_texts.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:46.656304Z","iopub.execute_input":"2024-05-29T08:19:46.656707Z","iopub.status.idle":"2024-05-29T08:19:46.678497Z","shell.execute_reply.started":"2024-05-29T08:19:46.656672Z","shell.execute_reply":"2024-05-29T08:19:46.676888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# n_epoches = 20","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:46.686500Z","iopub.execute_input":"2024-05-29T08:19:46.687005Z","iopub.status.idle":"2024-05-29T08:19:46.692572Z","shell.execute_reply.started":"2024-05-29T08:19:46.686962Z","shell.execute_reply":"2024-05-29T08:19:46.691164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epoches = 25\nfor epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for i, (texts, labels) in enumerate(tqdm(train_loader)):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for i, (texts, labels) in enumerate(tqdm(test_loader)):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:19:46.694366Z","iopub.execute_input":"2024-05-29T08:19:46.694828Z","iopub.status.idle":"2024-05-29T08:20:45.742206Z","shell.execute_reply.started":"2024-05-29T08:19:46.694785Z","shell.execute_reply":"2024-05-29T08:20:45.740457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:45.744119Z","iopub.execute_input":"2024-05-29T08:20:45.744583Z","iopub.status.idle":"2024-05-29T08:20:46.026000Z","shell.execute_reply.started":"2024-05-29T08:20:45.744500Z","shell.execute_reply":"2024-05-29T08:20:46.024604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import timeit\n# from tqdm import tqdm\n\n# n_epoches = 20\n# train_losses = []\n# val_losses = []\n\n# for epoch in range(n_epoches):\n#     train_loss = 0\n#     val_loss = 0\n    \n#     # Обучение\n#     start_train = timeit.default_timer()\n#     model.train()\n#     for i, (texts, labels) in enumerate(tqdm(train_loader)):\n#         # Перемещение данных на тот же устройство, что и модель\n#         texts = texts.float().to(device)\n#         labels = labels.to(device)\n\n#         outputs = model(texts)\n#         loss = criterion(outputs, labels)\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         train_loss += loss.item()\n#     end_train = timeit.default_timer()\n    \n#     # Валидация\n#     start_val = timeit.default_timer()\n#     model.eval()\n#     with torch.no_grad():\n#         for i, (texts, labels) in enumerate(tqdm(test_loader)):\n#             texts = texts.float().to(device)\n#             labels = labels.to(device)\n\n#             outputs = model(texts)\n#             loss = criterion(outputs, labels)\n\n#             val_loss += loss.item()\n#     end_val = timeit.default_timer()\n    \n#     train_loss /= len(train_loader)\n#     val_loss /= len(test_loader)\n#     train_losses.append(train_loss)\n#     val_losses.append(val_loss)\n\n#     print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n#     print(f'Time for training: {end_train - start_train:.4f} seconds')\n#     print(f'Time for validation: {end_val - start_val:.4f} seconds')\n\n# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(balanced_accuracy_score(test_labels, predictions))\nprint(precision_recall_fscore_support(test_labels, predictions, average='weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:46.027841Z","iopub.execute_input":"2024-05-29T08:20:46.028292Z","iopub.status.idle":"2024-05-29T08:20:46.150366Z","shell.execute_reply.started":"2024-05-29T08:20:46.028254Z","shell.execute_reply":"2024-05-29T08:20:46.149122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(balanced_accuracy_score(test_labels, predictions))\n# print(precision_recall_fscore_support(test_labels, predictions, average = 'weighted'))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:46.152005Z","iopub.execute_input":"2024-05-29T08:20:46.152418Z","iopub.status.idle":"2024-05-29T08:20:46.158653Z","shell.execute_reply.started":"2024-05-29T08:20:46.152383Z","shell.execute_reply":"2024-05-29T08:20:46.157163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Построение confusion matrix\n# labels = data['intent'].unique()  # получите уникальные метки классов\n# cm = confusion_matrix(test['intent'], predicted_intents, labels=labels)\n# plt.figure(figsize=(10,7))\n# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n# plt.xlabel('Predicted')\n# plt.ylabel('Truth')\n# plt.title(f'Logistic Regression')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:46.160234Z","iopub.execute_input":"2024-05-29T08:20:46.160814Z","iopub.status.idle":"2024-05-29T08:20:46.176197Z","shell.execute_reply.started":"2024-05-29T08:20:46.160778Z","shell.execute_reply":"2024-05-29T08:20:46.174572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotCM(test, predictions, name:'str'):\n    # Построение confusion matrix\n    labels = test['intent'].unique()  # получите уникальные метки классов\n    cm = confusion_matrix(test['intent'], predictions, labels=labels)\n    plt.figure(figsize=(10,7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted')\n    plt.ylabel('Truth')\n    plt.title(f'{name}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:46.178308Z","iopub.execute_input":"2024-05-29T08:20:46.178966Z","iopub.status.idle":"2024-05-29T08:20:46.198382Z","shell.execute_reply.started":"2024-05-29T08:20:46.178914Z","shell.execute_reply":"2024-05-29T08:20:46.196609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCM(test, predicted_intents,'LSTM+TF-IDF')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:20:46.200872Z","iopub.execute_input":"2024-05-29T08:20:46.201547Z","iopub.status.idle":"2024-05-29T08:20:47.740024Z","shell.execute_reply.started":"2024-05-29T08:20:46.201431Z","shell.execute_reply":"2024-05-29T08:20:47.738718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mini-LM\nsentence-transformers/all-MiniLM-L6-v2","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.preprocessing import LabelEncoder\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:08:47.062356Z","iopub.execute_input":"2024-05-29T08:08:47.062746Z","iopub.status.idle":"2024-05-29T08:08:47.724219Z","shell.execute_reply.started":"2024-05-29T08:08:47.062702Z","shell.execute_reply":"2024-05-29T08:08:47.722947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание пользовательского Dataset класса\nclass TextDataset(Dataset):\n    def __init__(self, embeddings, labels):\n        self.embeddings = embeddings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.embeddings[idx], self.labels[idx]\n    \n# Определение модели LSTM\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(LSTMClassifier, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        _, (hn, _) = self.lstm(x.unsqueeze(1))\n        out = self.fc(hn[-1])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:08:47.726190Z","iopub.execute_input":"2024-05-29T08:08:47.726694Z","iopub.status.idle":"2024-05-29T08:08:47.735306Z","shell.execute_reply.started":"2024-05-29T08:08:47.726658Z","shell.execute_reply":"2024-05-29T08:08:47.733893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:08:47.736817Z","iopub.execute_input":"2024-05-29T08:08:47.737335Z","iopub.status.idle":"2024-05-29T08:08:51.442023Z","shell.execute_reply.started":"2024-05-29T08:08:47.737272Z","shell.execute_reply":"2024-05-29T08:08:51.440642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Extract embeddings\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).pooler_output\n    test_embeddings = model(**test_encodings).pooler_output\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:08:51.443825Z","iopub.execute_input":"2024-05-29T08:08:51.444528Z","iopub.status.idle":"2024-05-29T08:10:06.696551Z","shell.execute_reply.started":"2024-05-29T08:08:51.444483Z","shell.execute_reply":"2024-05-29T08:10:06.695332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:06.698032Z","iopub.execute_input":"2024-05-29T08:10:06.698464Z","iopub.status.idle":"2024-05-29T08:10:06.718587Z","shell.execute_reply.started":"2024-05-29T08:10:06.698430Z","shell.execute_reply":"2024-05-29T08:10:06.717173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:06.720226Z","iopub.execute_input":"2024-05-29T08:10:06.721284Z","iopub.status.idle":"2024-05-29T08:10:41.449539Z","shell.execute_reply.started":"2024-05-29T08:10:06.721237Z","shell.execute_reply":"2024-05-29T08:10:41.448285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:41.451269Z","iopub.execute_input":"2024-05-29T08:10:41.451756Z","iopub.status.idle":"2024-05-29T08:10:41.457704Z","shell.execute_reply.started":"2024-05-29T08:10:41.451705Z","shell.execute_reply":"2024-05-29T08:10:41.456446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:41.459287Z","iopub.execute_input":"2024-05-29T08:10:41.459697Z","iopub.status.idle":"2024-05-29T08:10:41.559397Z","shell.execute_reply.started":"2024-05-29T08:10:41.459664Z","shell.execute_reply":"2024-05-29T08:10:41.558048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCM(test, predicted_intents, 'LSTM+mini-LM')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:41.561122Z","iopub.execute_input":"2024-05-29T08:10:41.561538Z","iopub.status.idle":"2024-05-29T08:10:43.044807Z","shell.execute_reply.started":"2024-05-29T08:10:41.561501Z","shell.execute_reply":"2024-05-29T08:10:43.043459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"M-USE","metadata":{}},{"cell_type":"code","source":"# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")\nmodel = AutoModel.from_pretrained(\"sadakmed/distiluse-base-multilingual-cased-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:10:43.051896Z","iopub.execute_input":"2024-05-29T08:10:43.053624Z","iopub.status.idle":"2024-05-29T08:11:00.698243Z","shell.execute_reply.started":"2024-05-29T08:10:43.053569Z","shell.execute_reply":"2024-05-29T08:11:00.696584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the text data\ntrain_encodings = tokenizer(train['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\ntest_encodings = tokenizer(test['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n\n# Извлечение эмбеддингов\nwith torch.no_grad():\n    train_embeddings = model(**train_encodings).last_hidden_state.mean(dim=1)\n    test_embeddings = model(**test_encodings).last_hidden_state.mean(dim=1)\n\nle = LabelEncoder()\n\n# Преобразование меток в числовые значения\ntrain_labels = le.fit_transform(train['intent'])\ntest_labels = le.transform(test['intent'])\n\n\n# Преобразование массивов numpy в тензоры PyTorch перед передачей в TextDataset\ntrain_dataset = TextDataset(train_embeddings, torch.tensor(train_labels))\ntest_dataset = TextDataset(test_embeddings, torch.tensor(test_labels))\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:11:00.704510Z","iopub.execute_input":"2024-05-29T08:11:00.704922Z","iopub.status.idle":"2024-05-29T08:15:22.627141Z","shell.execute_reply.started":"2024-05-29T08:11:00.704886Z","shell.execute_reply":"2024-05-29T08:15:22.625826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание и обучение модели\nmodel = LSTMClassifier(input_dim=train_embeddings.shape[1], hidden_dim=256, output_dim=len(le.classes_))\n\n# Перемещение модели на GPU, если он доступен\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\nval_losses = []\n\nn_epoches = 25","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:22.628973Z","iopub.execute_input":"2024-05-29T08:15:22.629408Z","iopub.status.idle":"2024-05-29T08:15:22.675451Z","shell.execute_reply.started":"2024-05-29T08:15:22.629374Z","shell.execute_reply":"2024-05-29T08:15:22.674302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(n_epoches):\n    train_loss = 0\n    val_loss = 0\n    # Обучение\n    model.train()\n    for texts, labels in tqdm(train_loader):\n        # Перемещение данных на тот же устройство, что и модель\n        texts = texts.float().to(device)\n        labels = labels.to(device)\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Валидация\n    model.eval()\n    with torch.no_grad():\n        for texts, labels in tqdm(test_loader):\n            texts = texts.float().to(device)\n            labels = labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item()\n\n    train_loss /= len(train_loader)\n    val_loss /= len(test_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n\n# Построение графика потерь\nplt.plot(range(1, n_epoches + 1), train_losses, label='Train Loss')\nplt.plot(range(1, n_epoches + 1), val_losses, label='Val Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:15:22.676942Z","iopub.execute_input":"2024-05-29T08:15:22.677323Z","iopub.status.idle":"2024-05-29T08:16:12.668417Z","shell.execute_reply.started":"2024-05-29T08:15:22.677290Z","shell.execute_reply":"2024-05-29T08:16:12.667173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Прогнозирование на тестовом наборе\n# predictions = []\n# with torch.no_grad():\n#     for i, (input_ids, labels) in enumerate(test_loader):\n#         input_ids = input_ids.float().to(device)\n\n#         outputs = model(input_ids)\n#         _, predicted = torch.max(outputs.data, 1)\n#         predictions.extend(predicted.cpu().numpy())\n\n# # Перевод меток обратно в исходные интенты\n# predicted_intents = le.inverse_transform(predictions)\n\n# print(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\n# print(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:16:12.670410Z","iopub.execute_input":"2024-05-29T08:16:12.670940Z","iopub.status.idle":"2024-05-29T08:16:12.677522Z","shell.execute_reply.started":"2024-05-29T08:16:12.670895Z","shell.execute_reply":"2024-05-29T08:16:12.676290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Прогнозирование на тестовом наборе\npredictions = []\nstart_test = timeit.default_timer()\nwith torch.no_grad():\n    for i, (input_ids, labels) in enumerate(test_loader):\n        input_ids = input_ids.float().to(device)\n\n        outputs = model(input_ids)\n        _, predicted = torch.max(outputs.data, 1)\n        predictions.extend(predicted.cpu().numpy())\nend_test = timeit.default_timer()\n\n# Перевод меток обратно в исходные интенты\npredicted_intents = le.inverse_transform(predictions)\n\n# Общее количество предсказанных ответов\nnum_predictions = len(predictions)\n\n# Среднее время на один ответ\naverage_time_per_response = (end_test - start_test) / num_predictions\n\nprint(f'Time for testing: {end_test - start_test:.4f} seconds')\nprint(f'Average time per response: {average_time_per_response:.6f} seconds')\nprint(\"precision_recall_fscore weighted\", precision_recall_fscore_support(test['intent'], predicted_intents, average='weighted'))\nprint(\"balanced_accuracy\", balanced_accuracy_score(test['intent'], predicted_intents))","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:16:12.679324Z","iopub.execute_input":"2024-05-29T08:16:12.680383Z","iopub.status.idle":"2024-05-29T08:16:12.795455Z","shell.execute_reply.started":"2024-05-29T08:16:12.680333Z","shell.execute_reply":"2024-05-29T08:16:12.794157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCM(test, predicted_intents, 'LSTM+m-USE')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T08:16:12.796904Z","iopub.execute_input":"2024-05-29T08:16:12.797307Z","iopub.status.idle":"2024-05-29T08:16:14.268030Z","shell.execute_reply.started":"2024-05-29T08:16:12.797271Z","shell.execute_reply":"2024-05-29T08:16:14.266764Z"},"trusted":true},"execution_count":null,"outputs":[]}]}